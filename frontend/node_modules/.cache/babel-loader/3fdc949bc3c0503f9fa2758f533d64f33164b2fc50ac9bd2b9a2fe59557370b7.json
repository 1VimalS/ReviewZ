{"ast":null,"code":"var _s = $RefreshSig$();\nimport { useNavigate } from 'react-router-dom';\nmodule.exports = SetUrl;\nfunction SetUrl(urlpath) {\n  fetch(\"/url\", {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\"\n    },\n    body: JSON.stringify({\n      url: urlpath\n    })\n  }) //http request ?url=urlpath\n  .then(function (response) {\n    return response.json();\n  }).then(function (data) {\n    NumberOfReviews(data);\n  }).catch(function (error) {\n    console.log(error);\n  });\n}\n_c = SetUrl;\nfunction NumberOfReviews(data) {\n  _s();\n  const navigate = useNavigate();\n  if (data[\"message\"] !== \"Collecting data from the US sites.\") {\n    alert(data[\"message\"]);\n    navigate('/');\n  } else {\n    document.getElementById(\"image-prep\").innerText = data[\"message\"];\n    fetch(\"/number-of-reviews\").then(function (response) {\n      return response.json();\n    }).then(function (data) {\n      ScrapeSite(data);\n    }).catch(function (error) {\n      console.log(error);\n    });\n  }\n}\n_s(NumberOfReviews, \"CzcTeTziyjMsSrAVmHuCCb6+Bfg=\", false, function () {\n  return [useNavigate];\n});\n_c2 = NumberOfReviews;\nfunction ScrapeSite(data) {\n  if (data[\"message\"] === \"Failed to collect the total number of reviews. Please try again.\") {\n    document.getElementById(\"image-prep\").innerText = data[\"message\"];\n  } else {\n    const maxPage = Math.ceil(data[\"message\"] / 10.0);\n    alert(maxPage);\n    for (let page = 1; page <= maxPage + 1; page++) {\n      fetch(\"/scraper\", {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\"\n        },\n        body: JSON.stringify({\n          \"page\": page\n        })\n      }) //http request ?page=(int)page\n      .then(function (response) {\n        return response.json();\n      }).then(function (data) {\n        AccumulateRawData(data, page, maxPage);\n      }).catch(function (error) {\n        console.log(error);\n      });\n    }\n  }\n}\n_c3 = ScrapeSite;\nfunction AccumulateRawData(data, page, maxPage) {\n  if (page <= maxPage) {\n    document.getElementById(\"image-prep\").innerText = \"Collecting the reviews, we are about \" + (page * 100 / maxPage).toFixed(0) + \"% done.\";\n  } else {\n    fetch(\"/tutorial-csv\").then(function (response) {\n      return response.json();\n    }).then(function (data) {\n      AnalyzeRawData(data);\n    }).catch(function (error) {\n      console.log(error);\n    });\n  }\n}\n_c4 = AccumulateRawData;\nfunction AnalyzeRawData(data) {\n  document.getElementById(\"image-prep\").innerText = data[\"message\"];\n  fetch(\"/analyzed-csv\").then(function (response) {\n    return response.json();\n  }).then(function (data) {\n    document.getElementById(\"image-prep\").innerText = data[\"message\"];\n  }).catch(function (error) {\n    console.log(error);\n  });\n}\n_c5 = AnalyzeRawData;\nvar _c, _c2, _c3, _c4, _c5;\n$RefreshReg$(_c, \"SetUrl\");\n$RefreshReg$(_c2, \"NumberOfReviews\");\n$RefreshReg$(_c3, \"ScrapeSite\");\n$RefreshReg$(_c4, \"AccumulateRawData\");\n$RefreshReg$(_c5, \"AnalyzeRawData\");","map":{"version":3,"names":["useNavigate","module","exports","SetUrl","urlpath","fetch","method","headers","body","JSON","stringify","url","then","response","json","data","NumberOfReviews","catch","error","console","log","navigate","alert","document","getElementById","innerText","ScrapeSite","maxPage","Math","ceil","page","AccumulateRawData","toFixed","AnalyzeRawData"],"sources":["C:/Users/gueren sanford/Desktop/reviewz/frontend/src/ScrapingAndAnalysis.js"],"sourcesContent":["import { useNavigate } from 'react-router-dom';\r\n\r\nmodule.exports = SetUrl\r\n\r\nfunction SetUrl (urlpath) {\r\n    fetch(\"/url\", {\r\n        method: \"POST\",\r\n        headers: {\"Content-Type\": \"application/json\"},\r\n        body: JSON.stringify({url: urlpath}), }) //http request ?url=urlpath\r\n    .then(function (response) {\r\n        return response.json();\r\n    })\r\n    .then(function (data) {\r\n        NumberOfReviews(data)\r\n    })\r\n    .catch(function (error) {\r\n        console.log(error)\r\n    })\r\n}\r\n\r\nfunction NumberOfReviews(data) {\r\n    const navigate = useNavigate();\r\n    if(data[\"message\"] !== \"Collecting data from the US sites.\")\r\n    {\r\n        alert(data[\"message\"])\r\n        navigate('/')\r\n    }\r\n    else\r\n    {\r\n        document.getElementById(\"image-prep\").innerText = data[\"message\"]\r\n        fetch(\"/number-of-reviews\")\r\n        .then(function (response) {\r\n            return response.json();\r\n        })\r\n        .then(function (data) {\r\n            ScrapeSite(data)\r\n        })\r\n        .catch(function (error) {\r\n            console.log(error)\r\n        })\r\n    }\r\n}\r\n\r\nfunction ScrapeSite(data) {\r\n    if(data[\"message\"] === \"Failed to collect the total number of reviews. Please try again.\")\r\n    {\r\n        document.getElementById(\"image-prep\").innerText = data[\"message\"]\r\n    }\r\n    else\r\n    {\r\n        const maxPage = Math.ceil(data[\"message\"]/10.0)\r\n        alert(maxPage)\r\n        for(let page = 1; page <= maxPage + 1; page++)\r\n        {\r\n            fetch(\"/scraper\", {\r\n                method: \"POST\",\r\n                headers: {\"Content-Type\": \"application/json\"},\r\n                body: JSON.stringify({\"page\": page}), }) //http request ?page=(int)page\r\n            .then(function (response) {\r\n                return response.json()\r\n            })\r\n            .then(function (data) {\r\n                AccumulateRawData(data, page, maxPage)\r\n            })\r\n            .catch(function (error) {\r\n                console.log(error)\r\n            })\r\n        }\r\n    }\r\n}\r\n\r\nfunction AccumulateRawData(data, page, maxPage) {\r\n    if(page <= maxPage)\r\n    {\r\n        document.getElementById(\"image-prep\").innerText = \"Collecting the reviews, we are about \" + ((page * 100) / maxPage).toFixed(0) + \"% done.\"\r\n    }\r\n    else\r\n    {\r\n        fetch(\"/tutorial-csv\")\r\n        .then(function (response) {\r\n            return response.json()\r\n        })\r\n        .then(function (data) {\r\n            AnalyzeRawData(data)\r\n        })\r\n        .catch(function (error) {\r\n            console.log(error)\r\n        })\r\n    }\r\n}\r\n\r\nfunction AnalyzeRawData(data) {\r\n    document.getElementById(\"image-prep\").innerText = data[\"message\"]\r\n    fetch(\"/analyzed-csv\")\r\n    .then(function (response) {\r\n        return response.json()\r\n    })\r\n    .then(function (data) {\r\n        document.getElementById(\"image-prep\").innerText = data[\"message\"]\r\n    })\r\n    .catch(function (error) {\r\n        console.log(error)\r\n    })\r\n}"],"mappings":";AAAA,SAASA,WAAW,QAAQ,kBAAkB;AAE9CC,MAAM,CAACC,OAAO,GAAGC,MAAM;AAEvB,SAASA,MAAM,CAAEC,OAAO,EAAE;EACtBC,KAAK,CAAC,MAAM,EAAE;IACVC,MAAM,EAAE,MAAM;IACdC,OAAO,EAAE;MAAC,cAAc,EAAE;IAAkB,CAAC;IAC7CC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;MAACC,GAAG,EAAEP;IAAO,CAAC;EAAG,CAAC,CAAC,CAAC;EAAA,CAC5CQ,IAAI,CAAC,UAAUC,QAAQ,EAAE;IACtB,OAAOA,QAAQ,CAACC,IAAI,EAAE;EAC1B,CAAC,CAAC,CACDF,IAAI,CAAC,UAAUG,IAAI,EAAE;IAClBC,eAAe,CAACD,IAAI,CAAC;EACzB,CAAC,CAAC,CACDE,KAAK,CAAC,UAAUC,KAAK,EAAE;IACpBC,OAAO,CAACC,GAAG,CAACF,KAAK,CAAC;EACtB,CAAC,CAAC;AACN;AAAC,KAdQf,MAAM;AAgBf,SAASa,eAAe,CAACD,IAAI,EAAE;EAAA;EAC3B,MAAMM,QAAQ,GAAGrB,WAAW,EAAE;EAC9B,IAAGe,IAAI,CAAC,SAAS,CAAC,KAAK,oCAAoC,EAC3D;IACIO,KAAK,CAACP,IAAI,CAAC,SAAS,CAAC,CAAC;IACtBM,QAAQ,CAAC,GAAG,CAAC;EACjB,CAAC,MAED;IACIE,QAAQ,CAACC,cAAc,CAAC,YAAY,CAAC,CAACC,SAAS,GAAGV,IAAI,CAAC,SAAS,CAAC;IACjEV,KAAK,CAAC,oBAAoB,CAAC,CAC1BO,IAAI,CAAC,UAAUC,QAAQ,EAAE;MACtB,OAAOA,QAAQ,CAACC,IAAI,EAAE;IAC1B,CAAC,CAAC,CACDF,IAAI,CAAC,UAAUG,IAAI,EAAE;MAClBW,UAAU,CAACX,IAAI,CAAC;IACpB,CAAC,CAAC,CACDE,KAAK,CAAC,UAAUC,KAAK,EAAE;MACpBC,OAAO,CAACC,GAAG,CAACF,KAAK,CAAC;IACtB,CAAC,CAAC;EACN;AACJ;AAAC,GArBQF,eAAe;EAAA,QACHhB,WAAW;AAAA;AAAA,MADvBgB,eAAe;AAuBxB,SAASU,UAAU,CAACX,IAAI,EAAE;EACtB,IAAGA,IAAI,CAAC,SAAS,CAAC,KAAK,kEAAkE,EACzF;IACIQ,QAAQ,CAACC,cAAc,CAAC,YAAY,CAAC,CAACC,SAAS,GAAGV,IAAI,CAAC,SAAS,CAAC;EACrE,CAAC,MAED;IACI,MAAMY,OAAO,GAAGC,IAAI,CAACC,IAAI,CAACd,IAAI,CAAC,SAAS,CAAC,GAAC,IAAI,CAAC;IAC/CO,KAAK,CAACK,OAAO,CAAC;IACd,KAAI,IAAIG,IAAI,GAAG,CAAC,EAAEA,IAAI,IAAIH,OAAO,GAAG,CAAC,EAAEG,IAAI,EAAE,EAC7C;MACIzB,KAAK,CAAC,UAAU,EAAE;QACdC,MAAM,EAAE,MAAM;QACdC,OAAO,EAAE;UAAC,cAAc,EAAE;QAAkB,CAAC;QAC7CC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;UAAC,MAAM,EAAEoB;QAAI,CAAC;MAAG,CAAC,CAAC,CAAC;MAAA,CAC5ClB,IAAI,CAAC,UAAUC,QAAQ,EAAE;QACtB,OAAOA,QAAQ,CAACC,IAAI,EAAE;MAC1B,CAAC,CAAC,CACDF,IAAI,CAAC,UAAUG,IAAI,EAAE;QAClBgB,iBAAiB,CAAChB,IAAI,EAAEe,IAAI,EAAEH,OAAO,CAAC;MAC1C,CAAC,CAAC,CACDV,KAAK,CAAC,UAAUC,KAAK,EAAE;QACpBC,OAAO,CAACC,GAAG,CAACF,KAAK,CAAC;MACtB,CAAC,CAAC;IACN;EACJ;AACJ;AAAC,MA1BQQ,UAAU;AA4BnB,SAASK,iBAAiB,CAAChB,IAAI,EAAEe,IAAI,EAAEH,OAAO,EAAE;EAC5C,IAAGG,IAAI,IAAIH,OAAO,EAClB;IACIJ,QAAQ,CAACC,cAAc,CAAC,YAAY,CAAC,CAACC,SAAS,GAAG,uCAAuC,GAAG,CAAEK,IAAI,GAAG,GAAG,GAAIH,OAAO,EAAEK,OAAO,CAAC,CAAC,CAAC,GAAG,SAAS;EAC/I,CAAC,MAED;IACI3B,KAAK,CAAC,eAAe,CAAC,CACrBO,IAAI,CAAC,UAAUC,QAAQ,EAAE;MACtB,OAAOA,QAAQ,CAACC,IAAI,EAAE;IAC1B,CAAC,CAAC,CACDF,IAAI,CAAC,UAAUG,IAAI,EAAE;MAClBkB,cAAc,CAAClB,IAAI,CAAC;IACxB,CAAC,CAAC,CACDE,KAAK,CAAC,UAAUC,KAAK,EAAE;MACpBC,OAAO,CAACC,GAAG,CAACF,KAAK,CAAC;IACtB,CAAC,CAAC;EACN;AACJ;AAAC,MAlBQa,iBAAiB;AAoB1B,SAASE,cAAc,CAAClB,IAAI,EAAE;EAC1BQ,QAAQ,CAACC,cAAc,CAAC,YAAY,CAAC,CAACC,SAAS,GAAGV,IAAI,CAAC,SAAS,CAAC;EACjEV,KAAK,CAAC,eAAe,CAAC,CACrBO,IAAI,CAAC,UAAUC,QAAQ,EAAE;IACtB,OAAOA,QAAQ,CAACC,IAAI,EAAE;EAC1B,CAAC,CAAC,CACDF,IAAI,CAAC,UAAUG,IAAI,EAAE;IAClBQ,QAAQ,CAACC,cAAc,CAAC,YAAY,CAAC,CAACC,SAAS,GAAGV,IAAI,CAAC,SAAS,CAAC;EACrE,CAAC,CAAC,CACDE,KAAK,CAAC,UAAUC,KAAK,EAAE;IACpBC,OAAO,CAACC,GAAG,CAACF,KAAK,CAAC;EACtB,CAAC,CAAC;AACN;AAAC,MAZQe,cAAc;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}